{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pickle\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the directory for test recordings, the path to the stored model, and the output file path/name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recording directory\n",
    "recording_dir = '../test_recordings/'\n",
    "\n",
    "# CNN model\n",
    "model_path = '..data/ResNet50_test'\n",
    "\n",
    "# Path to output prediction CSV\n",
    "output_path = './prediction_output.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run remaining cells to generate prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN input sample rate\n",
    "model_sample_rate = 48000\n",
    "\n",
    "test_recordings = os.listdir(recording_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN model\n",
    "\n",
    "model = model_from_json(open(model_path+'.json', 'r').read())\n",
    "model.load_weights(model_path+'.h5')\n",
    "class_dict = json.load(open(model_path+'_classes.json', 'r'))\n",
    "class_dict_rev = {(str(v[0])): k for k, v in class_dict.items()}\n",
    "\n",
    "print(model_path)\n",
    "print('Loaded model ')\n",
    "\n",
    "model_input_shape = model.get_layer(index=0).input_shape[1:]\n",
    "n_classes = model.get_layer(index=-1).output_shape[1:][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2data ( fig ):\n",
    "    \"\"\"\n",
    "    @brief Convert a Matplotlib figure to a 4D np array with RGBA channels and return it\n",
    "    @param fig a matplotlib figure\n",
    "    @return a np 3D array of RGBA values\n",
    "    \"\"\"\n",
    "    # draw the renderer\n",
    "    fig.canvas.draw ( )\n",
    " \n",
    "    # Get the RGBA buffer from the figure\n",
    "    w,h = fig.canvas.get_width_height()\n",
    "    buf = np.frombuffer ( fig.canvas.tostring_rgb(), dtype=np.uint8 )\n",
    "    buf.shape = ( w, h, 3 )\n",
    "    \n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Processing recording 1/1000 - project_1060/site_1008/2019/4/5CA3A3BE.flac\n",
      "Processing recording 2/1000 - project_1060/site_1008/2019/4/5CA3A86E.flac\n",
      "Processing recording 3/1000 - project_1060/site_1008/2019/4/5CA3AD1E.flac\n",
      "Processing recording 4/1000 - project_1060/site_1008/2019/4/5CA4E72E.flac\n",
      "Processing recording 5/1000 - project_1060/site_1008/2019/4/5CA4FC46.flac\n"
     ]
    }
   ],
   "source": [
    "### Run detections\n",
    "\n",
    "pixLen = 188 # 188 spectrogram pixels is ~2 seconds\n",
    "shft = 93 # %50 overlap between 188-length windows\n",
    "\n",
    "# Matrix of output predictions: rows are recordings, columns are species, \n",
    "prediction = np.zeros((len(uris), n_classes))\n",
    "\n",
    "# Function to break image into frames\n",
    "def divide_frames(im, w, s): \n",
    "    for i in range(0, im.shape[1], s):  \n",
    "        yield im[:, i:i + w] \n",
    "\n",
    "for n, j in enumerate(test_recordings): # loop over recordings\n",
    "            \n",
    "    print('Processing recording ' + str(j+1) + '/' + str(len(test_recordings)) + ' - ' + uris[j])\n",
    "    \n",
    "    audio_data, sampling_rate = librosa.load(recording_dir+j, sr=model_sample_rate)\n",
    "    \n",
    "    pxx = librosa.feature.melspectrogram(y = audio_data, \n",
    "                                           sr = sampling_rate,\n",
    "                                           n_fft=2048, \n",
    "                                           hop_length=512, \n",
    "                                           win_length=1024)\n",
    "    \n",
    "    X = []\n",
    "    for c, jj in enumerate(divide_frames(pxx, pixLen, shft)): # loop over frames\n",
    "        if jj.shape[1] != pixLen:\n",
    "            continue\n",
    "        dpi=100\n",
    "        fig = pyplot.figure(num=None, figsize=(224/dpi, 224/dpi), dpi=dpi)\n",
    "        pyplot.subplot(222)\n",
    "        ax = pyplot.axes()\n",
    "        ax.set_axis_off()\n",
    "        librosa.display.specshow(librosa.power_to_db(jj, ref=np.max))\n",
    "        img = fig2data(fig)\n",
    "        pyplot.close()\n",
    "        X.append(img/255.0)\n",
    "    X = np.stack(X)\n",
    "    \n",
    "    p = model.predict(X)\n",
    "            \n",
    "    for i in range(n_classes):\n",
    "        prediction[j, i] = max(p[:,i]) # Max-probability across 2s windows\n",
    "#         prediction[j, i, 1] = np.mean(np.sort(p[:,i])[-2:]) # Mean probability of top 2 windows\n",
    "\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of predictions\n",
    "prediction = pd.DataFrame(prediction[:,:,0])\n",
    "prediction.index = test_recordings\n",
    "prediction.columns = [class_dict[str(i)][0] for i in range(n_classes)]\n",
    "prediction.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sa] *",
   "language": "python",
   "name": "conda-env-sa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
