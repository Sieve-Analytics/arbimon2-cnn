{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the model name and training data paths below\n",
    "\n",
    "Separate directories for positive and negative examples of each class should be specified in train_dir_tp, and train_dir_fp, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_file_name = 'ResNet50_test' # name of trained model file\n",
    "model_dir = '../data' # path to directory where model will be stored\n",
    "\n",
    "train_dir_tp = '../data/train_tp' # directory with examples of true-positive spectrograms of each class\n",
    "train_dir_fp = '../data/train_fp' # directory with examples of false-positive spectrograms of each class\n",
    "\n",
    "num_classes = 24\n",
    "input_shape = [224, 224, 3]\n",
    "batch_size = 32\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run remaining cells to begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "target = []\n",
    "class_dict = dict()\n",
    "\n",
    "for c, i in enumerate(sorted(os.listdir(train_dir_tp))):\n",
    "    class_dict[c] = i\n",
    "    for j in os.listdir(train_dir_tp+'/'+i):\n",
    "        files.append(train_dir_tp+'/'+i+'/'+j)\n",
    "        tmp = np.empty(num_classes)\n",
    "        tmp[:] = np.nan\n",
    "        tmp[c] = int(1)\n",
    "        target.append(tmp)\n",
    "        \n",
    "for c, i in enumerate(sorted(os.listdir(train_dir_fp))):\n",
    "    class_dict[c] = i\n",
    "    for j in os.listdir(train_dir_fp+'/'+i):\n",
    "        files.append(train_dir_fp+'/'+i+'/'+j)\n",
    "        tmp = np.empty(num_classes)\n",
    "        tmp[:] = np.nan\n",
    "        tmp[c] = int(0)\n",
    "        target.append(tmp)\n",
    "        \n",
    "df_train = pd.concat([pd.DataFrame({'filename':files}),pd.DataFrame(np.asarray(target))],axis=1)\n",
    "\n",
    "print(len(df_train))\n",
    "validation_indices = np.random.choice(range(len(df_train)), size=int(len(df_train)*0.1), replace=False)\n",
    "df_validation = df_train.iloc[validation_indices]\n",
    "df_train.drop(df_train.index[validation_indices], inplace=True)\n",
    "print(len(df_train)+len(df_validation))\n",
    "df_validation.reset_index(drop=True, inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
    "                                                    y_col=range(num_classes),\n",
    "                                                    directory=None,\n",
    "                                                    target_size=input_shape[:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='raw')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(df_test,\n",
    "                                                        y_col=range(num_classes),\n",
    "                                                        directory=None,\n",
    "                                                        target_size=input_shape[:2],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='raw')\n",
    "\n",
    "def generator_wrapper(generator):\n",
    "    for batch_x, batch_y in generator:\n",
    "        yield (batch_x, np.row_stack(batch_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    return K.mean(K.mean(K.binary_crossentropy(tf.where(tf.math.is_nan(y_true), tf.zeros_like(y_true), y_true),\n",
    "                                        tf.multiply(y_pred, tf.cast(tf.logical_not(tf.math.is_nan(y_true)), tf.float32))), axis=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, only fit the new model top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model\n",
    "ResNet50_conv = ResNet50(weights='imagenet', \n",
    "                         include_top=False, \n",
    "                         input_shape=input_shape)\n",
    "\n",
    "# freeze convolutional layers\n",
    "for layer in ResNet50_conv.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# create the model\n",
    "inputs = layers.Input(input_shape)\n",
    "x = ResNet50_conv(inputs, training=False) # set batch norm. layers to inference mode\n",
    "x = layers.AveragePooling2D((7, 7))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# compile the model\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, decay=1e-7)\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model architecture\n",
    "model_json = model.to_json()\n",
    "with open(model_path+'/'+model_file_name+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "with open(model_path+'/'+model_file_name+'_classes.json', 'w') as f:\n",
    "    json.dump(class_dict, f)\n",
    "print('Saved model architecture')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model top\n",
    "model_history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch = len(train_generator),\n",
    "                                epochs = epochs,\n",
    "                                validation_data = validation_generator,\n",
    "                                validation_steps = len(validation_generator),\n",
    "                                verbose = 1)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, fine-tune the entire model with a lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze convolutional layers\n",
    "for layer in ResNet50_conv.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# recompile the model with a lower learning rate\n",
    "optimizer = keras.optimizers.Adam(lr=1e-6, decay=1e-7)\n",
    "model.compile(loss=masked_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit entire model\n",
    "model_history = model.fit_generator(train_generator,\n",
    "                                steps_per_epoch = len(train_generator),\n",
    "                                epochs = epochs,\n",
    "                                validation_data = validation_generator,\n",
    "                                validation_steps = len(validation_generator),\n",
    "                                verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained weights\n",
    "model.save_weights(model_path+'/'+model_file_name+'.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
